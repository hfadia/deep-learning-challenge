{"cells":[{"cell_type":"markdown","metadata":{"id":"m-fRZ-aDLB99"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"ooe9L4-ULB-A","executionInfo":{"status":"ok","timestamp":1685041015148,"user_tz":300,"elapsed":5835,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"849f9b99-d382-4c5f-aced-01e9473eeacd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        EIN                                      NAME APPLICATION_TYPE  \\\n","0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n","1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n","2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n","3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n","4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n","\n","        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n","0       Independent          C1000    ProductDev   Association       1   \n","1       Independent          C2000  Preservation  Co-operative       1   \n","2  CompanySponsored          C3000    ProductDev   Association       1   \n","3  CompanySponsored          C2000  Preservation         Trust       1   \n","4       Independent          C1000     Heathcare         Trust       1   \n","\n","      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n","0              0                      N     5000              1  \n","1         1-9999                      N   108590              1  \n","2              0                      N     5000              0  \n","3    10000-24999                      N     6692              1  \n","4  100000-499999                      N   142590              1  "],"text/html":["\n","  <div id=\"df-ac041070-2a69-4ec4-9228-1cc231476b02\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EIN</th>\n","      <th>NAME</th>\n","      <th>APPLICATION_TYPE</th>\n","      <th>AFFILIATION</th>\n","      <th>CLASSIFICATION</th>\n","      <th>USE_CASE</th>\n","      <th>ORGANIZATION</th>\n","      <th>STATUS</th>\n","      <th>INCOME_AMT</th>\n","      <th>SPECIAL_CONSIDERATIONS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10520599</td>\n","      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n","      <td>T10</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10531628</td>\n","      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Co-operative</td>\n","      <td>1</td>\n","      <td>1-9999</td>\n","      <td>N</td>\n","      <td>108590</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10547893</td>\n","      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n","      <td>T5</td>\n","      <td>CompanySponsored</td>\n","      <td>C3000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10553066</td>\n","      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n","      <td>T3</td>\n","      <td>CompanySponsored</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>10000-24999</td>\n","      <td>N</td>\n","      <td>6692</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10556103</td>\n","      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>Heathcare</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>100000-499999</td>\n","      <td>N</td>\n","      <td>142590</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac041070-2a69-4ec4-9228-1cc231476b02')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ac041070-2a69-4ec4-9228-1cc231476b02 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ac041070-2a69-4ec4-9228-1cc231476b02');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1}],"source":["# Import our dependencies\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import tensorflow as tf\n","\n","\n","#  Import and read the charity_data.csv.\n","import pandas as pd \n","application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n","application_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcGuWZQtLB-C"},"outputs":[],"source":["# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n","application_df = application_df.drop(columns=['EIN', 'NAME'])"]},{"cell_type":"code","source":["#Confirm columns have been dropped\n","application_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"J00ggNrjSgAP","executionInfo":{"status":"ok","timestamp":1685041015149,"user_tz":300,"elapsed":21,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"5f69575b-028c-486d-edab-ed007582dd5e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n","0              T10       Independent          C1000    ProductDev   \n","1               T3       Independent          C2000  Preservation   \n","2               T5  CompanySponsored          C3000    ProductDev   \n","3               T3  CompanySponsored          C2000  Preservation   \n","4               T3       Independent          C1000     Heathcare   \n","\n","   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n","0   Association       1              0                      N     5000   \n","1  Co-operative       1         1-9999                      N   108590   \n","2   Association       1              0                      N     5000   \n","3         Trust       1    10000-24999                      N     6692   \n","4         Trust       1  100000-499999                      N   142590   \n","\n","   IS_SUCCESSFUL  \n","0              1  \n","1              1  \n","2              0  \n","3              1  \n","4              1  "],"text/html":["\n","  <div id=\"df-768c54ff-552b-438f-b802-b04c1236fa99\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>APPLICATION_TYPE</th>\n","      <th>AFFILIATION</th>\n","      <th>CLASSIFICATION</th>\n","      <th>USE_CASE</th>\n","      <th>ORGANIZATION</th>\n","      <th>STATUS</th>\n","      <th>INCOME_AMT</th>\n","      <th>SPECIAL_CONSIDERATIONS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>T10</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Co-operative</td>\n","      <td>1</td>\n","      <td>1-9999</td>\n","      <td>N</td>\n","      <td>108590</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>T5</td>\n","      <td>CompanySponsored</td>\n","      <td>C3000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>T3</td>\n","      <td>CompanySponsored</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>10000-24999</td>\n","      <td>N</td>\n","      <td>6692</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>Heathcare</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>100000-499999</td>\n","      <td>N</td>\n","      <td>142590</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-768c54ff-552b-438f-b802-b04c1236fa99')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-768c54ff-552b-438f-b802-b04c1236fa99 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-768c54ff-552b-438f-b802-b04c1236fa99');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8Xkc6iYLB-D","executionInfo":{"status":"ok","timestamp":1685041015150,"user_tz":300,"elapsed":20,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"ff38acba-c383-4bfa-d764-febe15e6d5d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["APPLICATION_TYPE            17\n","AFFILIATION                  6\n","CLASSIFICATION              71\n","USE_CASE                     5\n","ORGANIZATION                 4\n","STATUS                       2\n","INCOME_AMT                   9\n","SPECIAL_CONSIDERATIONS       2\n","ASK_AMT                   8747\n","IS_SUCCESSFUL                2\n","dtype: int64"]},"metadata":{},"execution_count":4}],"source":["# Determine the number of unique values in each column.\n","application_df.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnim92tyLB-H","executionInfo":{"status":"ok","timestamp":1685041015150,"user_tz":300,"elapsed":17,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"53513ca8-6ce1-487f-a8d8-20f6e0d01736"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T3     27037\n","T4      1542\n","T6      1216\n","T5      1173\n","T19     1065\n","T8       737\n","T7       725\n","T10      528\n","T9       156\n","T13       66\n","T12       27\n","T2        16\n","T25        3\n","T14        3\n","T29        2\n","T15        2\n","T17        1\n","Name: APPLICATION_TYPE, dtype: int64"]},"metadata":{},"execution_count":5}],"source":["# Look at APPLICATION_TYPE value counts for binning\n","application_df['APPLICATION_TYPE'].value_counts()"]},{"cell_type":"code","source":["#bins = [0, 300, 600, 730, 1000, 1200, 1300, 1600, 28000]\n","group_names = [\"T9\", \"T10\", \"T7\", \"T8\", \"T19\", \"T5\", \"T6\", \"T4\", \"T3\"]\n","application_types_to_replace = application_df.loc[~application_df['APPLICATION_TYPE'].isin(group_names), 'APPLICATION_TYPE'].unique()\n","#group_names = np.array(group_names).astype('float32')\n","#pd.cut(application_df[\"APPLICATION_TYPE\"], bins, labels=group_names, include_lowest=True)\n","application_types_to_replace\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iedatEx0jNK8","executionInfo":{"status":"ok","timestamp":1685041015150,"user_tz":300,"elapsed":15,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"806f56c3-6443-4172-fea3-11ceb04f839b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['T2', 'T13', 'T12', 'T29', 'T25', 'T14', 'T17', 'T15'],\n","      dtype=object)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A4M60iPLB-K","executionInfo":{"status":"ok","timestamp":1685041015151,"user_tz":300,"elapsed":14,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"b20486d7-b0da-491f-d4c4-322a92176aef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T3       27037\n","T4        1542\n","T6        1216\n","T5        1173\n","T19       1065\n","T8         737\n","T7         725\n","T10        528\n","T9         156\n","Other      120\n","Name: APPLICATION_TYPE, dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# Choose a cutoff value and create a list of application types to be replaced\n","# use the variable name `application_types_to_replace`\n","\n","\n","# Replace in dataframe\n","for app in application_types_to_replace:\n","    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n","\n","# Check to make sure binning was successful\n","application_df['APPLICATION_TYPE'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQrDhIVSLB-L","executionInfo":{"status":"ok","timestamp":1685041015151,"user_tz":300,"elapsed":13,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"f78fd7d0-12a8-43d4-a814-128d442c10a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","         ...  \n","C4120        1\n","C8210        1\n","C2561        1\n","C4500        1\n","C2150        1\n","Name: CLASSIFICATION, Length: 71, dtype: int64"]},"metadata":{},"execution_count":8}],"source":["# Look at CLASSIFICATION value counts for binning\n","application_df['CLASSIFICATION'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lk1sS2sELB-M","executionInfo":{"status":"ok","timestamp":1685041015152,"user_tz":300,"elapsed":12,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"7c89a34f-065e-4fc9-952e-cb21475f29e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","C7000      777\n","C1700      287\n","C4000      194\n","C5000      116\n","C1270      114\n","C2700      104\n","C2800       95\n","C7100       75\n","C1300       58\n","C1280       50\n","C1230       36\n","C1400       34\n","C7200       32\n","C2300       32\n","C1240       30\n","C8000       20\n","C7120       18\n","C1500       16\n","C1800       15\n","C6000       15\n","C1250       14\n","C8200       11\n","C1238       10\n","C1278       10\n","C1235        9\n","C1237        9\n","C7210        7\n","C2400        6\n","C1720        6\n","C4100        6\n","C1257        5\n","C1600        5\n","C1260        3\n","C2710        3\n","C0           3\n","C3200        2\n","C1234        2\n","C1246        2\n","C1267        2\n","C1256        2\n","Name: CLASSIFICATION, dtype: int64"]},"metadata":{},"execution_count":9}],"source":["# You may find it helpful to look at CLASSIFICATION value counts >1\n","application_df['CLASSIFICATION'].value_counts().loc[lambda x : x>1]"]},{"cell_type":"code","source":["group_names = [\"C1000\", \"C2000\", \"C1200\", \"C3000\", \"C2100\"]\n","classifications_to_replace = application_df.loc[~application_df['CLASSIFICATION'].isin(group_names), 'CLASSIFICATION'].unique()\n","classifications_to_replace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psUxP1kL3FoV","executionInfo":{"status":"ok","timestamp":1685041015390,"user_tz":300,"elapsed":249,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"e5ea949e-655d-40e3-8a03-cbc3ab3eb685"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['C2700', 'C7000', 'C7200', 'C1700', 'C4000', 'C7100', 'C2800',\n","       'C6000', 'C1238', 'C5000', 'C7120', 'C1800', 'C4100', 'C1400',\n","       'C1270', 'C2300', 'C8200', 'C1500', 'C7210', 'C1300', 'C1230',\n","       'C1280', 'C1240', 'C2710', 'C2561', 'C1250', 'C8000', 'C1245',\n","       'C1260', 'C1235', 'C1720', 'C1257', 'C4500', 'C2400', 'C8210',\n","       'C1600', 'C1278', 'C1237', 'C4120', 'C2170', 'C1728', 'C1732',\n","       'C2380', 'C1283', 'C1570', 'C2500', 'C1267', 'C3700', 'C1580',\n","       'C2570', 'C1256', 'C1236', 'C1234', 'C1246', 'C2190', 'C4200',\n","       'C0', 'C3200', 'C5200', 'C1370', 'C2600', 'C1248', 'C6100',\n","       'C1820', 'C1900', 'C2150'], dtype=object)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-3MNrDGLB-N","executionInfo":{"status":"ok","timestamp":1685041015391,"user_tz":300,"elapsed":10,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"fd6a0fb9-8374-4f12-adef-d2fb2e503971"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","Other     2261\n","C3000     1918\n","C2100     1883\n","Name: CLASSIFICATION, dtype: int64"]},"metadata":{},"execution_count":11}],"source":["# Choose a cutoff value and create a list of classifications to be replaced\n","# use the variable name `classifications_to_replace`\n","#  \n","\n","# Replace in dataframe\n","for cls in classifications_to_replace:\n","    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n","    \n","# Check to make sure binning was successful\n","application_df['CLASSIFICATION'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"wqxLq2LmLB-N","executionInfo":{"status":"ok","timestamp":1685041015391,"user_tz":300,"elapsed":9,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"ed818325-57e3-40bc-9105-16b4f67f0377"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n","0           1      5000              1                       0   \n","1           1    108590              1                       0   \n","2           1      5000              0                       0   \n","3           1      6692              1                       0   \n","4           1    142590              1                       0   \n","...       ...       ...            ...                     ...   \n","34294       1      5000              0                       0   \n","34295       1      5000              0                       0   \n","34296       1      5000              0                       0   \n","34297       1      5000              1                       0   \n","34298       1  36500179              0                       0   \n","\n","       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n","0                         1                     0                    0   \n","1                         0                     0                    1   \n","2                         0                     0                    0   \n","3                         0                     0                    1   \n","4                         0                     0                    1   \n","...                     ...                   ...                  ...   \n","34294                     0                     0                    0   \n","34295                     0                     0                    0   \n","34296                     0                     0                    1   \n","34297                     0                     0                    0   \n","34298                     0                     0                    1   \n","\n","       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n","0                        0                    0                    0  ...   \n","1                        0                    0                    0  ...   \n","2                        0                    1                    0  ...   \n","3                        0                    0                    0  ...   \n","4                        0                    0                    0  ...   \n","...                    ...                  ...                  ...  ...   \n","34294                    1                    0                    0  ...   \n","34295                    1                    0                    0  ...   \n","34296                    0                    0                    0  ...   \n","34297                    0                    1                    0  ...   \n","34298                    0                    0                    0  ...   \n","\n","       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n","0                      0                       0                         0   \n","1                      1                       0                         0   \n","2                      0                       0                         0   \n","3                      0                       1                         0   \n","4                      0                       0                         1   \n","...                  ...                     ...                       ...   \n","34294                  0                       0                         0   \n","34295                  0                       0                         0   \n","34296                  0                       0                         0   \n","34297                  0                       0                         0   \n","34298                  0                       0                         0   \n","\n","       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n","0                       0                 0                       0   \n","1                       0                 0                       0   \n","2                       0                 0                       0   \n","3                       0                 0                       0   \n","4                       0                 0                       0   \n","...                   ...               ...                     ...   \n","34294                   0                 0                       0   \n","34295                   0                 0                       0   \n","34296                   0                 0                       0   \n","34297                   0                 0                       0   \n","34298                   0                 1                       0   \n","\n","       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n","0                    0                  0                         1   \n","1                    0                  0                         1   \n","2                    0                  0                         1   \n","3                    0                  0                         1   \n","4                    0                  0                         1   \n","...                ...                ...                       ...   \n","34294                0                  0                         1   \n","34295                0                  0                         1   \n","34296                0                  0                         1   \n","34297                0                  0                         1   \n","34298                0                  0                         1   \n","\n","       SPECIAL_CONSIDERATIONS_Y  \n","0                             0  \n","1                             0  \n","2                             0  \n","3                             0  \n","4                             0  \n","...                         ...  \n","34294                         0  \n","34295                         0  \n","34296                         0  \n","34297                         0  \n","34298                         0  \n","\n","[34299 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-085e4f0e-5784-4d80-916d-cee6fcf5f744\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATUS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","      <th>APPLICATION_TYPE_Other</th>\n","      <th>APPLICATION_TYPE_T10</th>\n","      <th>APPLICATION_TYPE_T19</th>\n","      <th>APPLICATION_TYPE_T3</th>\n","      <th>APPLICATION_TYPE_T4</th>\n","      <th>APPLICATION_TYPE_T5</th>\n","      <th>APPLICATION_TYPE_T6</th>\n","      <th>...</th>\n","      <th>INCOME_AMT_1-9999</th>\n","      <th>INCOME_AMT_10000-24999</th>\n","      <th>INCOME_AMT_100000-499999</th>\n","      <th>INCOME_AMT_10M-50M</th>\n","      <th>INCOME_AMT_1M-5M</th>\n","      <th>INCOME_AMT_25000-99999</th>\n","      <th>INCOME_AMT_50M+</th>\n","      <th>INCOME_AMT_5M-10M</th>\n","      <th>SPECIAL_CONSIDERATIONS_N</th>\n","      <th>SPECIAL_CONSIDERATIONS_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>108590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>6692</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>142590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34294</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34295</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34296</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34297</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34298</th>\n","      <td>1</td>\n","      <td>36500179</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34299 rows Ã— 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-085e4f0e-5784-4d80-916d-cee6fcf5f744')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-085e4f0e-5784-4d80-916d-cee6fcf5f744 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-085e4f0e-5784-4d80-916d-cee6fcf5f744');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["# Convert categorical data to numeric with `pd.get_dummies`\n","application_df = pd.get_dummies(application_df)\n","application_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9mK1VL5LB-O","executionInfo":{"status":"ok","timestamp":1685041015391,"user_tz":300,"elapsed":7,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"490de521-1314-4340-bff3-685bd33af836"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-76335cf01037>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n","  X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n"]}],"source":["# Split our preprocessed data into our features and target arrays\n","y = application_df[\"IS_SUCCESSFUL\"].values\n","X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n","\n","# Split the preprocessed data into a training and testing dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=58)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQeVAl8bLB-O"},"outputs":[],"source":["# Create a StandardScaler instances\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler\n","X_scaler = scaler.fit(X_train)\n","\n","# Scale the data\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"ML8HpFJpLB-P"},"source":["## Compile, Train and Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CznU7rb_LB-P","executionInfo":{"status":"ok","timestamp":1685041016776,"user_tz":300,"elapsed":1144,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"45004ad7-ce69-47f8-97f4-16f7694fddc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 8)                 360       \n","                                                                 \n"," dense_1 (Dense)             (None, 5)                 45        \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 411\n","Trainable params: 411\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n","number_input_features = len(X_train[0])\n","hidden_nodes_layer1 =  8\n","hidden_nodes_layer2 = 5\n","\n","nn = tf.keras.models.Sequential()\n","\n","# First hidden layer\n","nn.add(\n","    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",")\n","\n","\n","# Second hidden layer\n","nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n","\n","# Output layer\n","nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","# Check the structure of the model\n","nn.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CqKaLf2YLB-Q"},"outputs":[],"source":["# Compile the model\n","nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENjs-SX5LB-U","executionInfo":{"status":"ok","timestamp":1685041160231,"user_tz":300,"elapsed":143460,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"02dc8499-06ea-441a-cd7f-5dad6bcfaacb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","804/804 [==============================] - 4s 3ms/step - loss: 0.6323 - accuracy: 0.6412\n","Epoch 2/100\n","804/804 [==============================] - 2s 3ms/step - loss: 0.5827 - accuracy: 0.7185\n","Epoch 3/100\n","804/804 [==============================] - 3s 3ms/step - loss: 0.5697 - accuracy: 0.7254\n","Epoch 4/100\n","804/804 [==============================] - 2s 3ms/step - loss: 0.5621 - accuracy: 0.7297\n","Epoch 5/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7302\n","Epoch 6/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5562 - accuracy: 0.7304\n","Epoch 7/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7304\n","Epoch 8/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7301\n","Epoch 9/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5527 - accuracy: 0.7309\n","Epoch 10/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5517 - accuracy: 0.7312\n","Epoch 11/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7318\n","Epoch 12/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7310\n","Epoch 13/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7315\n","Epoch 14/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7315\n","Epoch 15/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7314\n","Epoch 16/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7315\n","Epoch 17/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7332\n","Epoch 18/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5485 - accuracy: 0.7317\n","Epoch 19/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7327\n","Epoch 20/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7329\n","Epoch 21/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7326\n","Epoch 22/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7329\n","Epoch 23/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7328\n","Epoch 24/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7326\n","Epoch 25/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7330\n","Epoch 26/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7324\n","Epoch 27/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7317\n","Epoch 28/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7328\n","Epoch 29/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7323\n","Epoch 30/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7317\n","Epoch 31/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7337\n","Epoch 32/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7322\n","Epoch 33/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7333\n","Epoch 34/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7330\n","Epoch 35/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7328\n","Epoch 36/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7332\n","Epoch 37/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7336\n","Epoch 38/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7337\n","Epoch 39/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7334\n","Epoch 40/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7332\n","Epoch 41/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7332\n","Epoch 42/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7332\n","Epoch 43/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7340\n","Epoch 44/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7342\n","Epoch 45/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7338\n","Epoch 46/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7334\n","Epoch 47/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7339\n","Epoch 48/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7334\n","Epoch 49/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7339\n","Epoch 50/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7333\n","Epoch 51/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7345\n","Epoch 52/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7346\n","Epoch 53/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7338\n","Epoch 54/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7339\n","Epoch 55/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7336\n","Epoch 56/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7345\n","Epoch 57/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7338\n","Epoch 58/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7332\n","Epoch 59/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7336\n","Epoch 60/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7342\n","Epoch 61/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7335\n","Epoch 62/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7335\n","Epoch 63/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7352\n","Epoch 64/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7343\n","Epoch 65/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7350\n","Epoch 66/100\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7343\n","Epoch 67/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7340\n","Epoch 68/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7341\n","Epoch 69/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7342\n","Epoch 70/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7334\n","Epoch 71/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7344\n","Epoch 72/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7338\n","Epoch 73/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7341\n","Epoch 74/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7344\n","Epoch 75/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7344\n","Epoch 76/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7345\n","Epoch 77/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7344\n","Epoch 78/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7351\n","Epoch 79/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7347\n","Epoch 80/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7352\n","Epoch 81/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7346\n","Epoch 82/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7342\n","Epoch 83/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7346\n","Epoch 84/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7346\n","Epoch 85/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7342\n","Epoch 86/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7346\n","Epoch 87/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7355\n","Epoch 88/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7345\n","Epoch 89/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7351\n","Epoch 90/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7341\n","Epoch 91/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7354\n","Epoch 92/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7345\n","Epoch 93/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7339\n","Epoch 94/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7349\n","Epoch 95/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7354\n","Epoch 96/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7349\n","Epoch 97/100\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7351\n","Epoch 98/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7347\n","Epoch 99/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7352\n","Epoch 100/100\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7342\n"]}],"source":["# Train the model\n","fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1gRU41rLB-W","executionInfo":{"status":"ok","timestamp":1685041160522,"user_tz":300,"elapsed":294,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"40a666b8-b108-4576-b23b-bfd55fcd74bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["268/268 - 0s - loss: 0.5528 - accuracy: 0.7263 - 356ms/epoch - 1ms/step\n","Loss: 0.5527627468109131, Accuracy: 0.7262973785400391\n"]}],"source":["# Evaluate the model using the test data\n","model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgNCHRdmLB-W"},"outputs":[],"source":["# Export our model to HDF5 file\n","\n","from tensorflow.keras.models import Model\n","\n","#Model.save('Desktop/AlphabetSoupCharity_Optimization.h5')\n","\n"]},{"cell_type":"code","source":["#new neural network model, implementing model optimization methods (2nd attempt)\n","# Create the Keras Sequential model\n","nn_model = tf.keras.models.Sequential()\n","\n","# Add our first Dense layer, including the input layer\n","nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=2))\n","\n","# Add the output layer that uses a probability activation function\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","# Check the structure of the Sequential model\n","nn_model.summary()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXdfzvtBO1Z7","executionInfo":{"status":"ok","timestamp":1685041160523,"user_tz":300,"elapsed":9,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"28a79a57-a8dc-4e07-d0fd-6ae577f9890f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 5)                 15        \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 21\n","Trainable params: 21\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Compile the Sequential model together and customize metrics\n","nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Fit the model to the training data\n","fit_model = nn.fit(X_train_scaled, y_train, epochs=200)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umAtsrnoR8Rg","executionInfo":{"status":"ok","timestamp":1685042037619,"user_tz":300,"elapsed":281027,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"ed6c642d-081a-4f53-9a54-ab225fad5e33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7357\n","Epoch 2/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7359\n","Epoch 3/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7360\n","Epoch 4/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7358\n","Epoch 5/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7357\n","Epoch 6/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7362\n","Epoch 7/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7357\n","Epoch 8/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7367\n","Epoch 9/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7356\n","Epoch 10/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 11/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7359\n","Epoch 12/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7359\n","Epoch 13/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n","Epoch 14/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7361\n","Epoch 15/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7357\n","Epoch 16/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7363\n","Epoch 17/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7360\n","Epoch 18/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7362\n","Epoch 19/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7358\n","Epoch 20/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7354\n","Epoch 21/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7356\n","Epoch 22/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7360\n","Epoch 23/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7361\n","Epoch 24/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7356\n","Epoch 25/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7365\n","Epoch 26/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n","Epoch 27/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7356\n","Epoch 28/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 29/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7358\n","Epoch 30/200\n","804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7358\n","Epoch 31/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n","Epoch 32/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 33/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7362\n","Epoch 34/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7364\n","Epoch 35/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 36/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7361\n","Epoch 37/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7365\n","Epoch 38/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7364\n","Epoch 39/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7357\n","Epoch 40/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7358\n","Epoch 41/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7365\n","Epoch 42/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7358\n","Epoch 43/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 44/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7365\n","Epoch 45/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7362\n","Epoch 46/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7359\n","Epoch 47/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n","Epoch 48/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7361\n","Epoch 49/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 50/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7362\n","Epoch 51/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7357\n","Epoch 52/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7355\n","Epoch 53/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7365\n","Epoch 54/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7362\n","Epoch 55/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7371\n","Epoch 56/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7366\n","Epoch 57/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7360\n","Epoch 58/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7367\n","Epoch 59/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7358\n","Epoch 60/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7362\n","Epoch 61/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 62/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7369\n","Epoch 63/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7369\n","Epoch 64/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 65/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7362\n","Epoch 66/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7357\n","Epoch 67/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7360\n","Epoch 68/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7359\n","Epoch 69/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7363\n","Epoch 70/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7363\n","Epoch 71/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7363\n","Epoch 72/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7363\n","Epoch 73/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 74/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7366\n","Epoch 75/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7365\n","Epoch 76/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7364\n","Epoch 77/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 78/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7362\n","Epoch 79/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7360\n","Epoch 80/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7364\n","Epoch 81/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7365\n","Epoch 82/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7367\n","Epoch 83/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 84/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7365\n","Epoch 85/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7364\n","Epoch 86/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7367\n","Epoch 87/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7365\n","Epoch 88/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 89/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7368\n","Epoch 90/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7366\n","Epoch 91/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7365\n","Epoch 92/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7362\n","Epoch 93/200\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7364\n","Epoch 94/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7370\n","Epoch 95/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7366\n","Epoch 96/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7367\n","Epoch 97/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7367\n","Epoch 98/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7367\n","Epoch 99/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7371\n","Epoch 100/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7363\n","Epoch 101/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7359\n","Epoch 102/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7366\n","Epoch 103/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7376\n","Epoch 104/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 105/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7368\n","Epoch 106/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 107/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7353\n","Epoch 108/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7363\n","Epoch 109/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7368\n","Epoch 110/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7368\n","Epoch 111/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7361\n","Epoch 112/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7364\n","Epoch 113/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7365\n","Epoch 114/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7362\n","Epoch 115/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7370\n","Epoch 116/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7370\n","Epoch 117/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7363\n","Epoch 118/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 119/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7370\n","Epoch 120/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7365\n","Epoch 121/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7360\n","Epoch 122/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7371\n","Epoch 123/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7365\n","Epoch 124/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7368\n","Epoch 125/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 126/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7364\n","Epoch 127/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7366\n","Epoch 128/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7363\n","Epoch 129/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7369\n","Epoch 130/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7362\n","Epoch 131/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7367\n","Epoch 132/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7368\n","Epoch 133/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7370\n","Epoch 134/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7371\n","Epoch 135/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7368\n","Epoch 136/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7365\n","Epoch 137/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7363\n","Epoch 138/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7365\n","Epoch 139/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7365\n","Epoch 140/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7362\n","Epoch 141/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7366\n","Epoch 142/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7367\n","Epoch 143/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7363\n","Epoch 144/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7371\n","Epoch 145/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7368\n","Epoch 146/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7369\n","Epoch 147/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7360\n","Epoch 148/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7360\n","Epoch 149/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7363\n","Epoch 150/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7365\n","Epoch 151/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7367\n","Epoch 152/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7365\n","Epoch 153/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7367\n","Epoch 154/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7365\n","Epoch 155/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7368\n","Epoch 156/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7372\n","Epoch 157/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7369\n","Epoch 158/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7366\n","Epoch 159/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7364\n","Epoch 160/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7360\n","Epoch 161/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7370\n","Epoch 162/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7365\n","Epoch 163/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7364\n","Epoch 164/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7365\n","Epoch 165/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n","Epoch 166/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n","Epoch 167/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7370\n","Epoch 168/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7365\n","Epoch 169/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7367\n","Epoch 170/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7370\n","Epoch 171/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7366\n","Epoch 172/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7364\n","Epoch 173/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7368\n","Epoch 174/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7363\n","Epoch 175/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7360\n","Epoch 176/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7368\n","Epoch 177/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7369\n","Epoch 178/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7371\n","Epoch 179/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7367\n","Epoch 180/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n","Epoch 181/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7358\n","Epoch 182/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7369\n","Epoch 183/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7366\n","Epoch 184/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7370\n","Epoch 185/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7369\n","Epoch 186/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7369\n","Epoch 187/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n","Epoch 188/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7369\n","Epoch 189/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7367\n","Epoch 190/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7370\n","Epoch 191/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7366\n","Epoch 192/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7369\n","Epoch 193/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7366\n","Epoch 194/200\n","804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7371\n","Epoch 195/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7367\n","Epoch 196/200\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7361\n","Epoch 197/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7364\n","Epoch 198/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7372\n","Epoch 199/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7367\n","Epoch 200/200\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7364\n"]}]},{"cell_type":"code","source":["model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcRkgpl1Tmqx","executionInfo":{"status":"ok","timestamp":1685042104775,"user_tz":300,"elapsed":883,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"93bd1b5f-1016-424f-9fa2-b9577c748bf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["268/268 - 0s - loss: 0.5539 - accuracy: 0.7277 - 369ms/epoch - 1ms/step\n","Loss: 0.5539416074752808, Accuracy: 0.7276967763900757\n"]}]},{"cell_type":"code","source":["#new neural network model, implementing model optimization methods (3rd attempt)\n","application_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"4XdMFZROViBT","executionInfo":{"status":"ok","timestamp":1685042213673,"user_tz":300,"elapsed":252,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"26b838de-57b1-4d7f-c373-1cd8e45b69bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n","0           1      5000              1                       0   \n","1           1    108590              1                       0   \n","2           1      5000              0                       0   \n","3           1      6692              1                       0   \n","4           1    142590              1                       0   \n","...       ...       ...            ...                     ...   \n","34294       1      5000              0                       0   \n","34295       1      5000              0                       0   \n","34296       1      5000              0                       0   \n","34297       1      5000              1                       0   \n","34298       1  36500179              0                       0   \n","\n","       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n","0                         1                     0                    0   \n","1                         0                     0                    1   \n","2                         0                     0                    0   \n","3                         0                     0                    1   \n","4                         0                     0                    1   \n","...                     ...                   ...                  ...   \n","34294                     0                     0                    0   \n","34295                     0                     0                    0   \n","34296                     0                     0                    1   \n","34297                     0                     0                    0   \n","34298                     0                     0                    1   \n","\n","       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n","0                        0                    0                    0  ...   \n","1                        0                    0                    0  ...   \n","2                        0                    1                    0  ...   \n","3                        0                    0                    0  ...   \n","4                        0                    0                    0  ...   \n","...                    ...                  ...                  ...  ...   \n","34294                    1                    0                    0  ...   \n","34295                    1                    0                    0  ...   \n","34296                    0                    0                    0  ...   \n","34297                    0                    1                    0  ...   \n","34298                    0                    0                    0  ...   \n","\n","       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n","0                      0                       0                         0   \n","1                      1                       0                         0   \n","2                      0                       0                         0   \n","3                      0                       1                         0   \n","4                      0                       0                         1   \n","...                  ...                     ...                       ...   \n","34294                  0                       0                         0   \n","34295                  0                       0                         0   \n","34296                  0                       0                         0   \n","34297                  0                       0                         0   \n","34298                  0                       0                         0   \n","\n","       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n","0                       0                 0                       0   \n","1                       0                 0                       0   \n","2                       0                 0                       0   \n","3                       0                 0                       0   \n","4                       0                 0                       0   \n","...                   ...               ...                     ...   \n","34294                   0                 0                       0   \n","34295                   0                 0                       0   \n","34296                   0                 0                       0   \n","34297                   0                 0                       0   \n","34298                   0                 1                       0   \n","\n","       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n","0                    0                  0                         1   \n","1                    0                  0                         1   \n","2                    0                  0                         1   \n","3                    0                  0                         1   \n","4                    0                  0                         1   \n","...                ...                ...                       ...   \n","34294                0                  0                         1   \n","34295                0                  0                         1   \n","34296                0                  0                         1   \n","34297                0                  0                         1   \n","34298                0                  0                         1   \n","\n","       SPECIAL_CONSIDERATIONS_Y  \n","0                             0  \n","1                             0  \n","2                             0  \n","3                             0  \n","4                             0  \n","...                         ...  \n","34294                         0  \n","34295                         0  \n","34296                         0  \n","34297                         0  \n","34298                         0  \n","\n","[34299 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-780938d3-6942-4fb1-ab40-6e3edd50f9b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATUS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","      <th>APPLICATION_TYPE_Other</th>\n","      <th>APPLICATION_TYPE_T10</th>\n","      <th>APPLICATION_TYPE_T19</th>\n","      <th>APPLICATION_TYPE_T3</th>\n","      <th>APPLICATION_TYPE_T4</th>\n","      <th>APPLICATION_TYPE_T5</th>\n","      <th>APPLICATION_TYPE_T6</th>\n","      <th>...</th>\n","      <th>INCOME_AMT_1-9999</th>\n","      <th>INCOME_AMT_10000-24999</th>\n","      <th>INCOME_AMT_100000-499999</th>\n","      <th>INCOME_AMT_10M-50M</th>\n","      <th>INCOME_AMT_1M-5M</th>\n","      <th>INCOME_AMT_25000-99999</th>\n","      <th>INCOME_AMT_50M+</th>\n","      <th>INCOME_AMT_5M-10M</th>\n","      <th>SPECIAL_CONSIDERATIONS_N</th>\n","      <th>SPECIAL_CONSIDERATIONS_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>108590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>6692</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>142590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34294</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34295</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34296</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34297</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34298</th>\n","      <td>1</td>\n","      <td>36500179</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34299 rows Ã— 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-780938d3-6942-4fb1-ab40-6e3edd50f9b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-780938d3-6942-4fb1-ab40-6e3edd50f9b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-780938d3-6942-4fb1-ab40-6e3edd50f9b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Look at ASK_AMT value counts\n","application_df['ASK_AMT'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fXExRdzWK5_","executionInfo":{"status":"ok","timestamp":1685042298536,"user_tz":300,"elapsed":309,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"f5b4c7be-0c8e-41c5-8ac9-ba0336cd25c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000        25398\n","10478           3\n","15583           3\n","63981           3\n","6725            3\n","            ...  \n","5371754         1\n","30060           1\n","43091152        1\n","18683           1\n","36500179        1\n","Name: ASK_AMT, Length: 8747, dtype: int64"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Drop the 'ASK_AMT column, not beneficial, maybe causing an outlier.\n","application_df = application_df.drop(columns=['ASK_AMT'])\n","application_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"ZgZqnaSWWi0b","executionInfo":{"status":"ok","timestamp":1685042471730,"user_tz":300,"elapsed":7,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"46d6a1d3-3f5f-4efe-97aa-fd342637f2a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       STATUS  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n","0           1              1                       0                     1   \n","1           1              1                       0                     0   \n","2           1              0                       0                     0   \n","3           1              1                       0                     0   \n","4           1              1                       0                     0   \n","...       ...            ...                     ...                   ...   \n","34294       1              0                       0                     0   \n","34295       1              0                       0                     0   \n","34296       1              0                       0                     0   \n","34297       1              1                       0                     0   \n","34298       1              0                       0                     0   \n","\n","       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n","0                         0                    0                    0   \n","1                         0                    1                    0   \n","2                         0                    0                    0   \n","3                         0                    1                    0   \n","4                         0                    1                    0   \n","...                     ...                  ...                  ...   \n","34294                     0                    0                    1   \n","34295                     0                    0                    1   \n","34296                     0                    1                    0   \n","34297                     0                    0                    0   \n","34298                     0                    1                    0   \n","\n","       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n","0                        0                    0                    0  ...   \n","1                        0                    0                    0  ...   \n","2                        1                    0                    0  ...   \n","3                        0                    0                    0  ...   \n","4                        0                    0                    0  ...   \n","...                    ...                  ...                  ...  ...   \n","34294                    0                    0                    0  ...   \n","34295                    0                    0                    0  ...   \n","34296                    0                    0                    0  ...   \n","34297                    1                    0                    0  ...   \n","34298                    0                    0                    0  ...   \n","\n","       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n","0                      0                       0                         0   \n","1                      1                       0                         0   \n","2                      0                       0                         0   \n","3                      0                       1                         0   \n","4                      0                       0                         1   \n","...                  ...                     ...                       ...   \n","34294                  0                       0                         0   \n","34295                  0                       0                         0   \n","34296                  0                       0                         0   \n","34297                  0                       0                         0   \n","34298                  0                       0                         0   \n","\n","       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n","0                       0                 0                       0   \n","1                       0                 0                       0   \n","2                       0                 0                       0   \n","3                       0                 0                       0   \n","4                       0                 0                       0   \n","...                   ...               ...                     ...   \n","34294                   0                 0                       0   \n","34295                   0                 0                       0   \n","34296                   0                 0                       0   \n","34297                   0                 0                       0   \n","34298                   0                 1                       0   \n","\n","       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n","0                    0                  0                         1   \n","1                    0                  0                         1   \n","2                    0                  0                         1   \n","3                    0                  0                         1   \n","4                    0                  0                         1   \n","...                ...                ...                       ...   \n","34294                0                  0                         1   \n","34295                0                  0                         1   \n","34296                0                  0                         1   \n","34297                0                  0                         1   \n","34298                0                  0                         1   \n","\n","       SPECIAL_CONSIDERATIONS_Y  \n","0                             0  \n","1                             0  \n","2                             0  \n","3                             0  \n","4                             0  \n","...                         ...  \n","34294                         0  \n","34295                         0  \n","34296                         0  \n","34297                         0  \n","34298                         0  \n","\n","[34299 rows x 44 columns]"],"text/html":["\n","  <div id=\"df-260b235a-ee74-4509-904d-c02653cc86d3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATUS</th>\n","      <th>IS_SUCCESSFUL</th>\n","      <th>APPLICATION_TYPE_Other</th>\n","      <th>APPLICATION_TYPE_T10</th>\n","      <th>APPLICATION_TYPE_T19</th>\n","      <th>APPLICATION_TYPE_T3</th>\n","      <th>APPLICATION_TYPE_T4</th>\n","      <th>APPLICATION_TYPE_T5</th>\n","      <th>APPLICATION_TYPE_T6</th>\n","      <th>APPLICATION_TYPE_T7</th>\n","      <th>...</th>\n","      <th>INCOME_AMT_1-9999</th>\n","      <th>INCOME_AMT_10000-24999</th>\n","      <th>INCOME_AMT_100000-499999</th>\n","      <th>INCOME_AMT_10M-50M</th>\n","      <th>INCOME_AMT_1M-5M</th>\n","      <th>INCOME_AMT_25000-99999</th>\n","      <th>INCOME_AMT_50M+</th>\n","      <th>INCOME_AMT_5M-10M</th>\n","      <th>SPECIAL_CONSIDERATIONS_N</th>\n","      <th>SPECIAL_CONSIDERATIONS_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34294</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34295</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34296</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34297</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34298</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34299 rows Ã— 44 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-260b235a-ee74-4509-904d-c02653cc86d3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-260b235a-ee74-4509-904d-c02653cc86d3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-260b235a-ee74-4509-904d-c02653cc86d3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n","number_input_features = len(X_train[0])\n","hidden_nodes_layer1 =  20\n","hidden_nodes_layer2 = 15\n","hidden_nodes_layer3 = 10\n","\n","nn = tf.keras.models.Sequential()\n","\n","# First hidden layer\n","nn.add(\n","    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",")\n","\n","\n","# Second hidden layer\n","nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n","\n","# Third hidden layer\n","nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n","\n","# Output layer\n","nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","# Check the structure of the model\n","nn.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnC_YUGuXEDa","executionInfo":{"status":"ok","timestamp":1685044542089,"user_tz":300,"elapsed":307,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"930d176d-b0d7-4d1b-801e-7c06b2fe65bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_14 (Dense)            (None, 20)                900       \n","                                                                 \n"," dense_15 (Dense)            (None, 15)                315       \n","                                                                 \n"," dense_16 (Dense)            (None, 10)                160       \n","                                                                 \n"," dense_17 (Dense)            (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 1,386\n","Trainable params: 1,386\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Compile the Sequential model together and customize metrics\n","nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Fit the model to the training data\n","fit_model = nn.fit(X_train_scaled, y_train, epochs=300)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdz_JfveXZtb","executionInfo":{"status":"ok","timestamp":1685045052166,"user_tz":300,"elapsed":503223,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"e3b21ba3-bb9f-48b7-90c6-e9fed2d56843"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5911 - accuracy: 0.7008\n","Epoch 2/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5599 - accuracy: 0.7260\n","Epoch 3/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7304\n","Epoch 4/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7311\n","Epoch 5/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7327\n","Epoch 6/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7322\n","Epoch 7/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7308\n","Epoch 8/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7321\n","Epoch 9/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7328\n","Epoch 10/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7341\n","Epoch 11/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7339\n","Epoch 12/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7341\n","Epoch 13/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7331\n","Epoch 14/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7332\n","Epoch 15/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7345\n","Epoch 16/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7341\n","Epoch 17/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7347\n","Epoch 18/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7357\n","Epoch 19/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7346\n","Epoch 20/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7353\n","Epoch 21/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7349\n","Epoch 22/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7363\n","Epoch 23/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7365\n","Epoch 24/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7354\n","Epoch 25/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7357\n","Epoch 26/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7359\n","Epoch 27/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7362\n","Epoch 28/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7353\n","Epoch 29/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7357\n","Epoch 30/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7357\n","Epoch 31/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7354\n","Epoch 32/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7360\n","Epoch 33/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7359\n","Epoch 34/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7361\n","Epoch 35/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7367\n","Epoch 36/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7360\n","Epoch 37/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7372\n","Epoch 38/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7362\n","Epoch 39/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7364\n","Epoch 40/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7358\n","Epoch 41/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7364\n","Epoch 42/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7367\n","Epoch 43/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7368\n","Epoch 44/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7359\n","Epoch 45/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7371\n","Epoch 46/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7364\n","Epoch 47/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7372\n","Epoch 48/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7373\n","Epoch 49/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7372\n","Epoch 50/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7378\n","Epoch 51/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7373\n","Epoch 52/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7373\n","Epoch 53/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7384\n","Epoch 54/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7364\n","Epoch 55/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7365\n","Epoch 56/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7360\n","Epoch 57/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7371\n","Epoch 58/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7372\n","Epoch 59/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7374\n","Epoch 60/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7375\n","Epoch 61/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7379\n","Epoch 62/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7367\n","Epoch 63/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7374\n","Epoch 64/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7378\n","Epoch 65/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7380\n","Epoch 66/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7381\n","Epoch 67/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7379\n","Epoch 68/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7378\n","Epoch 69/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7374\n","Epoch 70/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7371\n","Epoch 71/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7379\n","Epoch 72/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7375\n","Epoch 73/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7378\n","Epoch 74/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7381\n","Epoch 75/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7376\n","Epoch 76/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7380\n","Epoch 77/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7382\n","Epoch 78/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7377\n","Epoch 79/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7381\n","Epoch 80/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7385\n","Epoch 81/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7382\n","Epoch 82/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7385\n","Epoch 83/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7378\n","Epoch 84/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7379\n","Epoch 85/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7385\n","Epoch 86/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7389\n","Epoch 87/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7384\n","Epoch 88/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7378\n","Epoch 89/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7373\n","Epoch 90/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7385\n","Epoch 91/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7369\n","Epoch 92/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7378\n","Epoch 93/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.7381\n","Epoch 94/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7390\n","Epoch 95/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7393\n","Epoch 96/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7385\n","Epoch 97/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7377\n","Epoch 98/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7386\n","Epoch 99/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7377\n","Epoch 100/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7383\n","Epoch 101/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7379\n","Epoch 102/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7385\n","Epoch 103/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7382\n","Epoch 104/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7379\n","Epoch 105/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7384\n","Epoch 106/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7385\n","Epoch 107/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7391\n","Epoch 108/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7385\n","Epoch 109/300\n","804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7376\n","Epoch 110/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7381\n","Epoch 111/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7386\n","Epoch 112/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7387\n","Epoch 113/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7393\n","Epoch 114/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7393\n","Epoch 115/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7390\n","Epoch 116/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7392\n","Epoch 117/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7388\n","Epoch 118/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7392\n","Epoch 119/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7384\n","Epoch 120/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7397\n","Epoch 121/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7391\n","Epoch 122/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7383\n","Epoch 123/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7386\n","Epoch 124/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7386\n","Epoch 125/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7387\n","Epoch 126/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7380\n","Epoch 127/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7392\n","Epoch 128/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7387\n","Epoch 129/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7385\n","Epoch 130/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7399\n","Epoch 131/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7393\n","Epoch 132/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7390\n","Epoch 133/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7396\n","Epoch 134/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7384\n","Epoch 135/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7388\n","Epoch 136/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7391\n","Epoch 137/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7384\n","Epoch 138/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7391\n","Epoch 139/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7386\n","Epoch 140/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7386\n","Epoch 141/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7391\n","Epoch 142/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7391\n","Epoch 143/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7388\n","Epoch 144/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7390\n","Epoch 145/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7393\n","Epoch 146/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7386\n","Epoch 147/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7389\n","Epoch 148/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7388\n","Epoch 149/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7389\n","Epoch 150/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7386\n","Epoch 151/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7397\n","Epoch 152/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7389\n","Epoch 153/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7385\n","Epoch 154/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7389\n","Epoch 155/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7392\n","Epoch 156/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7390\n","Epoch 157/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7391\n","Epoch 158/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7386\n","Epoch 159/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7385\n","Epoch 160/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7394\n","Epoch 161/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7395\n","Epoch 162/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7388\n","Epoch 163/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7389\n","Epoch 164/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7390\n","Epoch 165/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7388\n","Epoch 166/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7393\n","Epoch 167/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7389\n","Epoch 168/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7382\n","Epoch 169/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n","Epoch 170/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7393\n","Epoch 171/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7390\n","Epoch 172/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7390\n","Epoch 173/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7389\n","Epoch 174/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7388\n","Epoch 175/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7388\n","Epoch 176/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7399\n","Epoch 177/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7389\n","Epoch 178/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7394\n","Epoch 179/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7399\n","Epoch 180/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n","Epoch 181/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7396\n","Epoch 182/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7391\n","Epoch 183/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7394\n","Epoch 184/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7394\n","Epoch 185/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7387\n","Epoch 186/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7397\n","Epoch 187/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7384\n","Epoch 188/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7390\n","Epoch 189/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7389\n","Epoch 190/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7391\n","Epoch 191/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7393\n","Epoch 192/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7397\n","Epoch 193/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7398\n","Epoch 194/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7395\n","Epoch 195/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7396\n","Epoch 196/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7393\n","Epoch 197/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7391\n","Epoch 198/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7398\n","Epoch 199/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7393\n","Epoch 200/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7395\n","Epoch 201/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7395\n","Epoch 202/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7400\n","Epoch 203/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7393\n","Epoch 204/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7396\n","Epoch 205/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7395\n","Epoch 206/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7397\n","Epoch 207/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7391\n","Epoch 208/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7399\n","Epoch 209/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7388\n","Epoch 210/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7394\n","Epoch 211/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7400\n","Epoch 212/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7393\n","Epoch 213/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7391\n","Epoch 214/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7392\n","Epoch 215/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7391\n","Epoch 216/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7395\n","Epoch 217/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n","Epoch 218/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7398\n","Epoch 219/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7393\n","Epoch 220/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7393\n","Epoch 221/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7388\n","Epoch 222/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7388\n","Epoch 223/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7402\n","Epoch 224/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7396\n","Epoch 225/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7399\n","Epoch 226/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7401\n","Epoch 227/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7388\n","Epoch 228/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7397\n","Epoch 229/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7396\n","Epoch 230/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7401\n","Epoch 231/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7399\n","Epoch 232/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7399\n","Epoch 233/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7395\n","Epoch 234/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7391\n","Epoch 235/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7392\n","Epoch 236/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7400\n","Epoch 237/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7395\n","Epoch 238/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7393\n","Epoch 239/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7398\n","Epoch 240/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7395\n","Epoch 241/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7396\n","Epoch 242/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7399\n","Epoch 243/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7381\n","Epoch 244/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7397\n","Epoch 245/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7392\n","Epoch 246/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n","Epoch 247/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7396\n","Epoch 248/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7393\n","Epoch 249/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7402\n","Epoch 250/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7391\n","Epoch 251/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7393\n","Epoch 252/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7393\n","Epoch 253/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7400\n","Epoch 254/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7394\n","Epoch 255/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7393\n","Epoch 256/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7398\n","Epoch 257/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7395\n","Epoch 258/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7386\n","Epoch 259/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7397\n","Epoch 260/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7391\n","Epoch 261/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7395\n","Epoch 262/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7398\n","Epoch 263/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7394\n","Epoch 264/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7396\n","Epoch 265/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7389\n","Epoch 266/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7400\n","Epoch 267/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7397\n","Epoch 268/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7395\n","Epoch 269/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7395\n","Epoch 270/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7395\n","Epoch 271/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7397\n","Epoch 272/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7399\n","Epoch 273/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7402\n","Epoch 274/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n","Epoch 275/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7393\n","Epoch 276/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7403\n","Epoch 277/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7400\n","Epoch 278/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7403\n","Epoch 279/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n","Epoch 280/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7402\n","Epoch 281/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7399\n","Epoch 282/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7393\n","Epoch 283/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7398\n","Epoch 284/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7400\n","Epoch 285/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7392\n","Epoch 286/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7396\n","Epoch 287/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7400\n","Epoch 288/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7395\n","Epoch 289/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7402\n","Epoch 290/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7395\n","Epoch 291/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7400\n","Epoch 292/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7406\n","Epoch 293/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7399\n","Epoch 294/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7388\n","Epoch 295/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7395\n","Epoch 296/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7399\n","Epoch 297/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7400\n","Epoch 298/300\n","804/804 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7400\n","Epoch 299/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7402\n","Epoch 300/300\n","804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7396\n"]}]},{"cell_type":"code","source":["model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLnszptTYeru","executionInfo":{"status":"ok","timestamp":1685046080548,"user_tz":300,"elapsed":520,"user":{"displayName":"Haddi Fadia","userId":"00012957538429685898"}},"outputId":"64f1e496-bad6-43f7-cdf9-610423e72a5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["268/268 - 0s - loss: 0.5689 - accuracy: 0.7276 - 299ms/epoch - 1ms/step\n","Loss: 0.5688904523849487, Accuracy: 0.727580189704895\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.-1.-1"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[{"file_id":"1hyDOwmTU4HsGMy4vEtwg8DdeZ_dgdAO5","timestamp":1684990990209}]}},"nbformat":4,"nbformat_minor":0}